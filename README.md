# TinyML
Tiny Machine Learning, is a rapidly growing field focused on developing machine learning models that can run on extremely resource-constrained devices. These devices often have limited memory, processing power, and battery life, such as microcontrollers, sensors, and other IoT devices.


## The roles of senors in TinyML
The Role of Sensors in TinyML Applications
Sensors are important for machine learning applications as they act as a vehicle between algorithmic resources and characteristics of the physical environment. Today there is a continued push towards low-cost and high-performance sensors, especially for applications such as air quality monitoring and predictive maintenance. There are two main types of sensing: in situ and remote sensing. 

In situ sensors come in numerous forms and each have a particular sensing mechanism. For example, the sensing mechanism may involve chemical reactions, light, or measuring voltages from material changes caused by stress. In situ sensors are often characterized as physical sensors and are constrained to measure local attributes at the location of the sensing element. Remote sensing methods work at a range, and are almost always optical techniques. For example, temperature can be measured at a distance using an infrared thermometer, and gas concentrations in the atmosphere can be measured by columnar measurements made by satellites in low Earth orbit. In situ sensors can use optical mechanisms, but are often distinguished because they only measure local attributes.

In TinyML, we are typically interested in sensor data in the form of an image or time series, enabling us to perform spatial or time series analysis using machine learning models. The utility of sensors for tiny machine learning allows real-time feedback and monitoring of the local environment, either at the point of the sensing element or at a distance using remote sensing methods. For example, an array of in situ sensors each with gas sensing elements can be used to monitor pollution levels across a university campus, or surrounding an industrial facility. Similarly, an example of a remote sensing method might be a camera used to monitor local weather conditions based on the appearance of overlying clouds - perhaps useful in locations with limited internet access. 

For a sensor outputting a time series, the sensor measurement can be used as a single feature in a machine learning model. A segment of the time series might also be used for classification or anomaly detection purposes. For an image-based method, the bitmap can be flattened and each pixel passed as a feature in a neural network. 

Sensors can be used individually or can be combined to produce synergistic effects. This provides even more powerful capabilities, especially when combined with online machine learning. Perhaps the most utilized example of this for TinyML currently is the combination of an accelerometer and gyroscope. These devices are often present in smartphones and other embedded devices, and can be used together to differentiate between complex 6-axis movements. These allow your smartphone to know when it has been picked up, or to know when the holder has fallen over. They can also be used in more complex devices such as drones to estimate the local wind speed and direction via how it perturbs from normal operation. Other sensors apart from accelerometers and gyroscopes are also common. Vibration sensors are becoming increasingly common in industrial applications for predictive maintenance. These sensors are used with the aim to improve machinery uptime by detecting anomalous vibrations and repairing them before a catastrophic failure occurs.

Using sensors for embedded machine learning presents several additional challenges. Firstly, sensors have a finite working life, and the designer should bear this in mind during development. For example, we might not want a complex sensing system to become unusable if a single sensor becomes defective, and we might want it to default  to a specific action in the event of a failure. Sensors also tend to exhibit noise and drift, which is often infeasible to remove or model statistically. TinyML systems should be robust enough that they are not adversely impacted by this noise or drift during regular operations. In a similar vein, sensors that are not properly isolated electrically can have the potential to distort other measurements. Finally, the more sensors that are present in a given system, the more complex and power-hungry it becomes. To be an adept user of TinyML, it is not enough to know about machine learning and embedded systems, but also mindful of the constraints imposed by electrical and mechanical engineering challenges.

To overcome the above challenges, the following rules of thumb are recommended:

1 - Collect rich data. In the machine learning world, data is power. A sufficiently large amount of data should be collected to ensure that our TinyML models are able to effectively approximate the distribution of the data. More data never hurts!

2 - Don’t over-engineer your system. While it may seem attractive to add fifteen sensors to a system, we should follow Occam’s razor when engineering our system that “entities should not be multiplied without necessity”. Being intelligent and yet parsimonious with our sensor selection will minimize the possibility of running into hardware complications.

3 - Plan to cover all possible sources of variation. The statistical power of our model will always be limited by the data at hand. Consequently, it is helpful to cover as much ground as possible without conflicting with #2. This can involve collecting data that covers edge cases as well as using additional sensors that are expected to provide some additional explanatory power to the model.

4 - Use the highest workable sampling rate. Although it is highly expensive to transmit and store high-frequency data, we limit these issues when we are using TinyML systems since inferences are made on-device and streamlined to minimize storage. It is much easier to downsample data when there is too much than to upsample it when there is not enough. Thus, when collecting data to use for model training, it is recommended to obtain the highest resolution data possible to provide flexibility in downstream data engineering processes.

Regardless of whether you are using sounds, images, vibrations, electrical signals, or other sensor data, these signals can be combined and used to train machine learning models to help model, classify, or predict events at the edge in real-time using inexpensive microcontrollers, which is a very powerful tool indeed.


**Steps we follow:**
First, we go for Data Engineering, then Model Engineering, thirdly Model Deployment, and lastly Product analysis

![ML Lifecycle](https://github.com/AI-Native-Computing-Organization/TinyML/blob/testing/src/ml_cycle.png)

**Machine Learning Lifecycle**
The development of a machine learning model follows a multi-step design methodology, commonly referred to as the machine learning lifecycle. Diagrams typically illustrate this lifecycle using a varying set of discrete steps. This methodology is also applicable to tiny machine learning applications, albeit with different requirements to conventional machine learning models. Some of the most important steps in the machine learning lifecycle are as follows:

Design Requirements. The first stage of the machine learning lifecycle is  where the application requirements are established. For tiny machine learning applications, hardware constraints (e.g., memory and storage footprint, latency) are often the most pressing requirements. Other requirements can include temporal resolution of data, the number of inferences per second, or minimum model accuracy. This step, whilst being the least well-defined, is the most crucial step, as it sets the scene for the remainder of the lifecycle. The more clearly defined the design criteria are, the easier it is to evaluate the model in later stages. Data requirements, such as the variable of interest and potential feature variables, can also be specified during this stage.

Data Collection/Curation. In this stage, design requirements are known and data begin to be collected that are suspected to aid in predicting the variable of interest. This can often involve active data collection or curation of information from external sources, such as pre-existing datasets (e.g., CIFAR10, ImageNet). This is often one of the most time consuming stages, as it can be difficult and time-consuming to curate a sufficiently large dataset, simultaneously ensuring to minimize dataset bias. No data analysis is performed during this stage. In Course 2, we will learn the challenges associated with data collection for different types of sensors that serve as inputs for tiny machine learning applications.

Exploratory Data Analysis/Data Preprocessing. During this phase, the collected data is analyzed to determine which features are most informative at predicting the variable of interest. Feature engineering is common at this stage, extracting new information from available data. An example of this would be to extract the day of the week or whether it is a weekend from a time variable. Preprocessing involves ensuring the data follows standard modeling assumptions (e.g., are normally distributed) or manipulating data to meet these assumptions (e.g., log transformations on highly skewed variables). Data imputation is also typically done to appropriately fill in or remove missing data, and invalid or duplicate data is handled accordingly. When we develop our keyword spotting model, we will learn how to pre-process the audio signal.

Model Development. All of the previous stages focused on the design aspects, as well as the procurement and analysis of data. These stages often make up the dominant proportion of the time in the machine learning lifecycle. Once a viable dataset is available, the next stage is creating a suitable machine learning model. There are a plethora of machine learning techniques that have various pros and cons. One of the jobs of a machine learning practitioner is selecting an appropriate model for the task at hand. For example, basic linear regression may be suitable in environments where interpretability is key, but are constrained to the set of linear functions. This may present bias in situations where the distribution of data is highly non-linear in feature space, which can result in poor model accuracy. Conversely, neural networks may offer high performance as they are able to model the non-linear data distribution more effectively, but are less interpretable to the user. Keeping in mind the design requirements is important during this stage to know on what grounds to evaluate different models. One thing we will do in Course 2 is to understand the different model development approaches. Training a neural network from scratch is not always necessary.

Model Validation. It is commonplace to generate multiple models and to compare their performance on an unseen data set, known as the test set. The presence of a test set helps to ensure that the model has effectively modeled the distribution of data and has not overfit to points in the training set. The design criteria help to determine what metrics should be used in comparing the performance of various models. For example, if accuracy is the dominant metric, the model with the highest accuracy should be chosen. This stage can also be used to determine whether specific features improved or hindered model performance (e.g., by analyzing the relative importance of features or by successively removing variables and retraining the model, known as ablation study). But there is more to model validation than just looking at the model metrics. We will discover how to think about metrics in a new light, specifically, from an application deployment perspective. 

Model Deployment. The last stage of the lifecycle involves the deployment of the model in the production environment. For tiny machine learning applications, this is one of the most important stages. The model size must be reduced sufficiently to fit on the embedded device through various means such as model compression (i.e., model distillation), type conversion (e.g.., changing model weights from floats to integers), and lossless compression (e.g., Huffman encoding). The model must then be compiled into a format compatible with the end device. We will learn about “quantization” and use it to optimize the model size for performance and latency to make sure we are building sufficiently ‘tiny’ models. We will use TensorFlow’s quantization API, as well as understand what’s going on behind the scenes. 

After all of these stages, continuous monitoring of the model in the production environment is typically necessary to ensure that it is working effectively. If, after all of these steps, the performance of the model is unsatisfactory in the production environment, the model must be 
updated. This can be done using new design requirements, data, or modeling techniques. This is the essence of the machine learning lifecycle.

**We create our ML models using TensorFlow,  TensorFlow Lite to make it a lighter version and Lite micro is for much lighter ones**
![image](https://github.com/user-attachments/assets/243c9e31-a815-4c98-afda-4a4b9b83e065)

